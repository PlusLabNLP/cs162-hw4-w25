# UCLA CS162 Course - HW4

In this question, you'll work with a recent Large Language Model Gemma 2 2B. You'll learn how to use the model and its tokenizer, generate text using greedy decoding, top-p sampling, and top-k sampling, and evaluate the model’s basic arithmetic capabilities on a simple dataset.

We recommend using Google Colab and copying the notebook to your Google Drive:

<a href="https://colab.research.google.com/github/PlusLabNLP/cs162-hw4-w25/blob/main/HW4.ipynb"><img alt="Colab Demo" src="https://img.shields.io/badge/​-Open%20in%20Colab-blue?logo=googlecolab&logoColor=F9AB00&style=flat"></a>

## Submission Instructions:
* Do not modify any of the grading code.
* After completing the assignment, download both the .ipynb and .py files. (Go to File → Download)
* Submit both files on Gradescope under "Homework 4 - Coding".
* Do not change the filenames—keep them as "HW4.ipynb" and "HW4.py".
* Ensure all outputs are printed in the notebook (.ipynb) and do not clear the outputs before submission.
* The autograder results will be available immediately—please check to ensure you receive the full score.
